# AR Final Project: Head Pose Estimation for Virtual Interactive Nose Pointer 

This project includes a python code for robust head pose estimatation using a webcam. Based on this estimation, a virtual pointer is generated from the nose of a person in view of the camera. This pointer is interactive and plays different sounds based of the button that is being touched on the screen using this pointer. 

## Dependencies
The code was written in jupyter notebook using python 3.9.12. A logitech C920 1080p webcam was used to capture the video. In addition, the following libraries were used:
1. opencv
2. dlib
3. mediapipe
4. numpy
5. matplotlib
6. cv2
7. os
8. glob
9. imutils
10. playsound

Make sure you have these before running the code. 

## How to run the code?

After installing the dependencies, run the first seven cells of the notebook.
Note: It might take some time for the program to initialize the webcam to capture the video. A separate window is created that shows the view of the webcam with the pointer as well as the buttons. The video capturing can be terminated by pressing the escape button

## Video
The demo of the project can be found here: https://github.com/Vanderbilt-AR-8395-2022-Spring/Mahrukh_Tauseef/blob/main/Final_Project.mp4


